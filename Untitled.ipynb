{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9411625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import ImageFilter\n",
    "\n",
    "height, width = 224, 224\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "def generate_data(DIR):\n",
    "    datagen = ImageDataGenerator(rescale=1./255.)\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        DIR,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        class_mode='binary',\n",
    "        target_size=(height, width),\n",
    "        classes={'Normal': 0, 'Viral Pneumonia': 1,'Covid': 2}\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# TRAINING_DIR = '../input/covid19-image-dataset/Covid19-dataset/train'\n",
    "# TESTING_DIR = '../input/covid19-image-dataset/Covid19-dataset/test'\n",
    "dir =r'C:\\Users\\Ayush\\Desktop\\ be project\\COVID-19_Radiography_Dataset' \n",
    "TRAINING_DIR = ' '\n",
    "TESTING_DIR = ' '\n",
    "train_generator = generate_data(TRAINING_DIR)\n",
    "test_generator = generate_data(TESTING_DIR)\n",
    "\n",
    "total_image = np.concatenate([train_generator.labels,test_generator.labels])\n",
    "\n",
    "print('\\n\\n',{'Normal_cases':len(np.where(total_image==0)[0]),\n",
    "      'Viral_Pneumonia_cases':len(np.where(total_image==1)[0]),\n",
    "             'Covid_cases':len(np.where(total_image==2)[0])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Images demonstration\"\"\"\n",
    "def image_plot(generator,image_numbers):\n",
    "    img_feature = generator[0][0][:image_numbers]\n",
    "    img_label = generator[0][1][:image_numbers]\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for i in range(image_numbers):\n",
    "        ax = plt.subplot(math.ceil(image_numbers/4),4, i + 1)\n",
    "        plt.imshow(img_feature[i])\n",
    "        plt.title(\"Normal\" if img_label[i] == 0 else \"Viral Pneumonia\" if img_label[i] == 1 else \"Covid\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "image_plot(train_generator,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c40cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VGG16 implementation\n",
    "The reason that I added 2 more dense layers is to identify more clearly from the grayscale image.\n",
    "\n",
    "The dropout layers are regularization for preventing overfitting.\"\"\"\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "input_shape = (height, width, 3)\n",
    "base_model = tf.keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model_vgg16 = tf.keras.Sequential()\n",
    "model_vgg16.add(base_model)\n",
    "model_vgg16.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "model_vgg16.add(tf.keras.layers.Flatten())\n",
    "model_vgg16.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_vgg16.add(tf.keras.layers.Dropout(0.5))\n",
    "model_vgg16.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_vgg16.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_vgg16.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model_vgg16.compile(loss='SparseCategoricalCrossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "model_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e027d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg16_best.h5', monitor='acc', verbose=1, mode='max',save_best_only=True)\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\",restore_best_weights=True, patience=5)\n",
    "\n",
    "callbacks_list = [checkpoint,early]\n",
    "\n",
    "history = model_vgg16.fit(\n",
    "        train_generator,\n",
    "        validation_data = test_generator,\n",
    "        #steps_per_epoch=10,\n",
    "        epochs=50, \n",
    "        shuffle=False, \n",
    "        verbose=True,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba957c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve\n",
    "def plot_learning_curve(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, label='training acc')\n",
    "    plt.plot(epochs, val_acc, label='validation acc')\n",
    "    plt.legend();\n",
    "    plt.figure();\n",
    "\n",
    "    plt.plot(epochs, loss, label='training loss')\n",
    "    plt.plot(epochs, val_loss, label='validation loss')\n",
    "    plt.legend();\n",
    "\n",
    "plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model_vgg16.evaluate(train_generator)\n",
    "test_result = model_vgg16.evaluate(test_generator)\n",
    "\n",
    "no_augmented_df = pd.DataFrame(zip(train_result,test_result),columns=['Train','Val'],index=['Loss','Acc'])\n",
    "no_augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = np.array([])\n",
    "xtest = []\n",
    "\n",
    "for i in range(math.ceil(len(test_generator.classes)/batch_size)):\n",
    "    xtest.append(test_generator[i][0]) \n",
    "    ytest= np.concatenate((ytest,test_generator[i][-1])) \n",
    "    \n",
    "xtest = np.concatenate((xtest),axis=0)\n",
    "\n",
    "ypred_prob =model_vgg16.predict(xtest)\n",
    "ypred = np.argmax(ypred_prob,axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "hm = sns.heatmap(confusion_matrix(ytest,ypred), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal','Viral Penumonia','Covid'],yticklabels=['Normal','Viral Penumonia','Covid'])  \n",
    "hm.set(xlabel='Predicted_labels')\n",
    "hm.set(ylabel='True_labels')\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show the wrong classified image\"\"\"\n",
    "#Extract wrong classification index\n",
    "wrong_pred = np.where(ypred!=ytest)[0]\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i,n in enumerate(wrong_pred):\n",
    "    ax = plt.subplot(math.ceil(len(wrong_pred)/4),4, i + 1)\n",
    "    plt.imshow(xtest[n])\n",
    "    plt.title(\"Normal\" if ypred[n] == 0 else \"Viral Pneumonia\" if ypred[n] == 1 else \"Covid\",color='r')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding image augmentation\"\"\"\n",
    "def generate_data_augmented(DIR):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255.,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "    generator = datagen.flow_from_directory(\n",
    "        TRAINING_DIR,\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode='binary',\n",
    "        target_size=(height, width),\n",
    "        classes={'Normal': 0, 'Viral Pneumonia': 1,'Covid': 2}\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "aug_train_generator = generate_data_augmented(TRAINING_DIR)\n",
    "\n",
    "image_plot(aug_train_generator,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg16_best.h5', monitor='acc', verbose=1, mode='max',save_best_only=True)\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\",restore_best_weights=True, patience=10)\n",
    "\n",
    "callbacks_list = [checkpoint,early]\n",
    "\n",
    "history = model_vgg16.fit(\n",
    "        aug_train_generator,\n",
    "        validation_data = test_generator,\n",
    "        #steps_per_epoch=10,\n",
    "        epochs=60, \n",
    "        shuffle=False, \n",
    "        verbose=True,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556062",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model_vgg16.evaluate(train_generator)\n",
    "test_result = model_vgg16.evaluate(test_generator)\n",
    "\n",
    "augmented_df = pd.DataFrame(zip(train_result,test_result),columns=['Train','Val'],index=['Loss','Acc'])\n",
    "augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array([])\n",
    "xtrain = []\n",
    "\n",
    "for i in range(math.ceil(len(train_generator.classes)/batch_size)):\n",
    "    xtrain.append(train_generator[i][0]) \n",
    "    ytrain= np.concatenate((ytrain,train_generator[i][-1])) \n",
    "    \n",
    "xtrain = np.concatenate((xtrain),axis=0)\n",
    "\n",
    "ypred_prob =model_vgg16.predict(xtrain)\n",
    "ypred = np.argmax(ypred_prob,axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "hm = sns.heatmap(confusion_matrix(ytrain,ypred), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal','Viral Penumonia','Covid'],yticklabels=['Normal','Viral Penumonia','Covid'])  \n",
    "hm.set(xlabel='Predicted_labels')\n",
    "hm.set(ylabel='True_labels')\n",
    "print(classification_report(ytrain,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4799757",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = np.array([])\n",
    "xtest = []\n",
    "\n",
    "for i in range(math.ceil(len(test_generator.classes)/batch_size)):\n",
    "    xtest.append(test_generator[i][0]) \n",
    "    ytest= np.concatenate((ytest,test_generator[i][-1])) \n",
    "    \n",
    "xtest = np.concatenate((xtest),axis=0)\n",
    "\n",
    "ypred_prob =model_vgg16.predict(xtest)\n",
    "ypred = np.argmax(ypred_prob,axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "hm = sns.heatmap(confusion_matrix(ytest,ypred), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal','Viral Penumonia','Covid'],yticklabels=['Normal','Viral Penumonia','Covid'])  \n",
    "hm.set(xlabel='Predicted_labels')\n",
    "hm.set(ylabel='True_labels')\n",
    "print(classification_report(ytest,ypred))\n",
    "              precision    recall  f1-score   suppo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
